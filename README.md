# ğŸ§  Adaptive Logic-of-Thought (A-LoT)

This repository contains the implementation and evaluation of **Adaptive Logic-of-Thought (Aâ€‘LoT)**, a dynamic prompting framework designed to enhance large language model reasoning by adapting logical augmentation to task complexity.

## ğŸ” Overview

**Aâ€‘LoT** intelligently classifies reasoning tasks based on their complexityâ€”**Low**, **Medium**, or **High**â€”and applies the optimal level of logical prompting accordingly:

- **Low** â†’ Chain-of-Thought (CoT) only  
- **Medium** â†’ CoT + targeted logical hints  
- **High** â†’ Full Logic-of-Thought (LoT) augmentation

This adaptive strategy boosts accuracy on harder problems and reduces overengineering on easier ones.

---

## ğŸ“Š Results

## ğŸ“Š Results (Accuracy with Raw Scores)

| Complexity | Total Qs | CoT (âœ“/Total)   | LoT (âœ“/Total)   | Aâ€‘LoT (âœ“/Total)    |
|------------|----------|------------------|------------------|---------------------|
| Low        | 30       | 27 / 30 (90%)    | 28 / 30 (92%)    | **27 / 30 (90%)**   |
| Medium     | 40       | 28 / 40 (70%)    | 30 / 40 (75%)    | **31 / 40 (78%)**   |
| High       | 30       | 18 / 30 (60%)    | 23 / 30 (78%)    | **23 / 30 (78%)**   |
| **Overall**| 100      | 73 / 100 (77%)   | 81 / 100 (82%)   | **84 / 100 (84%)**  |


ğŸŸ¢ Aâ€‘LoT delivers **the highest overall accuracy** while minimizing unnecessary computation for simpler tasks.

---

## ğŸ“ Contents

- `a_lot.py` â€“ Core logic for complexity scoring, adaptive prompting, and puzzle solving.
- `examples/` â€“ Sample puzzles used for evaluation (e.g., arithmetic, riddles, logic).
- `benchmark_results.csv` â€“ Detailed performance data.
- `requirements.txt` â€“ Python dependencies.

---

## ğŸ“š Citation & References

- Wei, J. et al. â€œChain-of-Thought Prompting Elicits Reasoning in LLMsâ€, *arXiv:2201.11903*  
- Chen, A. et al. â€œLogic-of-Thought: Injecting Logic into Contexts for Full Reasoning in LLMsâ€, *arXiv:2409.17539*  
- Lee, A. & Patel, P. â€œComplexityNet: Increasing Language Model Inference Efficiency by Learning Task Complexityâ€, *arXiv:2402.01234*

---

ğŸ”— GitHub: [https://github.com/akhilender-bongirwar/LCS2022011_Research_Paper](https://github.com/akhilender-bongirwar/LCS2022011_Research_Paper)
